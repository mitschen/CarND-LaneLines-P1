{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "## Project: **Finding Lane Lines on the Road**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LaneFinder**\n",
    "\n",
    "class representing the pipeline. The static function *findLanes* is execution step by step:\n",
    "* convertToGrayScale\n",
    "* applyCannyEdgeDetection\n",
    "* stripViewport\n",
    "* applyHoughTransformation\n",
    " * this guy contains a filtering based on angles as well as \n",
    " * the merging to vectors\n",
    "* highlightLanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LaneFinder(object):\n",
    "    def __init__(self, mpimage):\n",
    "        self.img = mpimage;\n",
    "        self.laneImg = mpimage\n",
    "        self.imgDepth = None\n",
    "    \n",
    "    def show(self):\n",
    "        plt.imshow(self.img)\n",
    "        plt.show()\n",
    "        \n",
    "    def convertToGrayScale(self):\n",
    "        self.laneImg = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY)\n",
    "        self.imgDepth = 'gray'\n",
    "        \n",
    "    def stripViewport(self):\n",
    "        mask = np.zeros_like(self.laneImg)\n",
    "        xsize = mask.shape[1]\n",
    "        ysize = mask.shape[0]\n",
    "        polyPtr = np.array(\n",
    "            [ \n",
    "                [[xsize / 100 * 4, ysize], [xsize / 100 * 46, ysize /10*6],\n",
    "                 [xsize / 100 * 54, ysize/10*6], [xsize / 100 * 96, ysize]\n",
    "                ]\n",
    "            ], dtype=np.int32)\n",
    "        cv2.fillPoly(mask, polyPtr, 255)\n",
    "        self.laneImg = cv2.bitwise_and(self.laneImg, mask)  \n",
    "        \n",
    "    def applyCannyEdgeDetection(self):\n",
    "        # Define a kernel size and apply Gaussian smoothing\n",
    "        kernel_size = 5\n",
    "        blur_gray = cv2.GaussianBlur(self.laneImg,(kernel_size, kernel_size),0)\n",
    "        # Define our parameters for Canny and apply\n",
    "        low_threshold = 50\n",
    "        high_threshold = 150\n",
    "        self.laneImg = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "        \n",
    "    def __applyAngleFiltering(self, lines):\n",
    "        angle = 35\n",
    "        threshold = 15\n",
    "        \n",
    "        lowerThresh = math.radians(angle-threshold)\n",
    "        upperThresh = math.radians(angle+threshold ) \n",
    "        resultingLines = []\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                alpha = math.fabs(math.atan((y2-y1)/(x2-x1)))\n",
    "                if(lowerThresh <= alpha and alpha <= upperThresh):\n",
    "                    resultingLines.append( [x1, y1, x2, y2] )\n",
    "        return np.array(resultingLines).reshape(-1,1,4)\n",
    "    \n",
    "    def __mapStretchesOnVector(self, lines):\n",
    "        m1 = []\n",
    "        m2 = []\n",
    "        b1 = []\n",
    "        b2 = []\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                m = (y2-y1)/(x2-x1)\n",
    "                if m<0:\n",
    "                    m1.append(m)\n",
    "                    b1.append(y1-m*x1)\n",
    "                else:\n",
    "                    m2.append(m)\n",
    "                    b2.append(y1-m*x1)\n",
    "        #chosen the median instead of average to be more\n",
    "        #safe against spikes\n",
    "        m1 = np.median(m1)\n",
    "        m2 = np.median(m2)\n",
    "        b1 = np.median(b1)\n",
    "        b2 = np.median(b2)\n",
    "        #make sure that we do not report invalid data\n",
    "        lines = []\n",
    "        ysize = self.img.shape[0]\n",
    "        if(not np.isnan(m1)):\n",
    "            lines.append( [(ysize-b1)/m1, ysize, (ysize/10*6-b1)/m1, ysize/10*6] )\n",
    "        if( not np.isnan(m2)):\n",
    "            lines.append([(ysize-b2)/m2, ysize, (ysize/10*6-b2)/m2, ysize/10*6])\n",
    "            \n",
    "        #bring it into format    \n",
    "        lines = np.array(lines, dtype=np.int32).reshape(-1,1,4);\n",
    "        \n",
    "        return lines\n",
    "        \n",
    "    def applyHoughTransformation(self):\n",
    "        rho = 2 # distance resolution in pixels of the Hough grid\n",
    "        theta = 1 * np.pi/180 # angular resolution in radians of the Hough grid\n",
    "        threshold = 15     # minimum number of votes (intersections in Hough grid cell)\n",
    "        min_line_length = 20 #minimum number of pixels making up a line\n",
    "        max_line_gap = 20    # maximum gap in pixels between connectable line segments\n",
    "        \n",
    "        lines = cv2.HoughLinesP(self.laneImg, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "        \n",
    "        lines = self.__applyAngleFiltering(lines)\n",
    "        lines = self.__mapStretchesOnVector(lines)\n",
    "        #copy the \n",
    "        lineSpace = np.zeros_like(self.laneImg)#np.copy(self.img)*0\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(lineSpace,(x1,y1),(x2,y2),(255,0,0),8)\n",
    "        self.laneImg = lineSpace\n",
    "\n",
    "    def highlightLanes(self):\n",
    "        colorLineSpace = np.dstack((self.laneImg, self.laneImg*0, self.laneImg*0)) \n",
    "        self.img = cv2.addWeighted(self.img, 0.8, colorLineSpace, 1.0, 0)                 \n",
    "        \n",
    "        \n",
    "        \n",
    "    #static create\n",
    "    def createFromImage(str_path):\n",
    "        img = mpimg.imread(str_path)\n",
    "        return LaneFinder(img)\n",
    "    \n",
    "    def findLanes(image):\n",
    "        #this is the pipeline\n",
    "        #unfortunately i saw the P1.ipynb after I've written the complete solution\n",
    "        finder = LaneFinder(image)\n",
    "        finder.convertToGrayScale()\n",
    "        finder.applyCannyEdgeDetection()\n",
    "        finder.stripViewport()\n",
    "        #contains a angle based filtering \n",
    "        #as well as a mapping from all line-stretches to a single line\n",
    "        finder.applyHoughTransformation()\n",
    "        finder.highlightLanes()\n",
    "        return finder.img\n",
    "\n",
    "    #declaration of statics\n",
    "    createFromImage = staticmethod(createFromImage)\n",
    "    findLanes = staticmethod(findLanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Images**\n",
    "\n",
    "Build your pipeline to work on the images in the directory \"test_images\"\n",
    "You should make sure your pipeline works well on these images before you try the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "imageDir = str(os.path.join(os.getcwd(),\"test_images\"))\n",
    "for filename in os.listdir(imageDir):\n",
    "    if filename.endswith(\".jpg\") and not filename.startswith(\"res_\"):\n",
    "        fqp = os.path.join(imageDir, filename)\n",
    "        fqp_out = os.path.join(imageDir,\"res_\" + filename)\n",
    "        resultingImage = LaneFinder.findLanes(mpimg.imread(fqp))\n",
    "        #for convertion from RGB to BGR to allow to store as jpeg again\n",
    "        resultingImage = cv2.cvtColor(resultingImage, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(fqp_out, resultingImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply LaneFinder on videos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SolidYellowLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▉| 681/682 [00:25<00:00, 26.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "#output path & filename\n",
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "\n",
    "clip1 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "#apply LaneFinder on videoclip\n",
    "yellow_clip = clip1.fl_image(lambda x: LaneFinder.findLanes(x))\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SolidWhiteRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 221/222 [00:07<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "#output path & filename\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "\n",
    "clip2 = VideoFileClip('test_videos/solidWhiteRight.mp4')\n",
    "#apply LaneFinder on videoclip\n",
    "white_clip = clip2.fl_image(lambda x: LaneFinder.findLanes(x))\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
